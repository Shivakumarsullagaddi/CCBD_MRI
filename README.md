# CCBD_MRI

## 1. Problem Definition & Data Preparation

**Goal:** Detect and analyze hippocampal and cortical atrophy in MRI scans for Alzheimer‚Äôs disease research.

**Dataset:** Organized MRI NIfTI files by diagnostic class (`AD`, `CN`, `MCI`), with each subject having an MRI and metadata.

---

## 2. Initial Experiments: 2D Classification

- **Started with:** 2D CNNs on individual MRI slices.
- **Challenge:** 2D models failed to capture 3D anatomical context, leading to limited accuracy and poor generalization.

---

## 3. Transition to 3D Deep Learning

- **Moved to:** 3D ResNet and 3D CNNs, processing full MRI volumes.
- **Benefit:** Captured spatial relationships between slices, improving classification performance.
- **Problem:** Computational requirements increased; model training was slower and required more memory.








## üìò Learnings

- **3D Images** require more computation (GPUs).  
  - üß† They **take significantly more time** when run on CPU.

- When the **Dataset is SMALL** and the model is **Overfitting**:  
  - ‚úÖ Use **Data Augmentation**  
  - ‚úÖ Apply **Regularization**

- When the model has **Poor Generalization**:  
  - üîÅ Use **Transfer Learning**

- When facing issues in **loading huge datasets** during training on GPU:  
  - ‚öôÔ∏è Use **Mixed Precision Training**

- When all else is good (no issues):  
  - üîß Try tuning **Epochs**, **Batch Size**, **Learning Rate**, and observe performance.




## üöß Problem Faced

While performing deep learning and medical image processing tasks, I encountered multiple platform-related limitations:

### üîπ GPU Access in Google Colab
- Although Colab provides access to GPUs (e.g., NVIDIA T4), memory-intensive processing can lead to **CUDA out-of-memory errors** or **runtime disconnections** after the 2-hour session limit.

### üîπ Switching to Kaggle
- Kaggle notebooks offer GPU support, but if **CUDA runs out of memory**, the corresponding cell is **automatically killed** without warning or traceback, making it hard to debug or resume the process.

### üîπ Using Local Resources
- Running models locally provides full control and avoids runtime interruptions, but it **requires sufficient memory and disk space** to store large datasets (such as MRI, DICOM, or NIfTI files)

---

### ‚úÖ Conclusion

Each platform comes with trade-offs:

- **Colab** is good for small to medium workloads.
- **Kaggle** is reliable for structured competition environments but lacks graceful error handling.
- **Local machines** require strong hardware, especially for large-scale datasets.









